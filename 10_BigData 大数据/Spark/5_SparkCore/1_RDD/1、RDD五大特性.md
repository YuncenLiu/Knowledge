# RDD

分布式计算需要：

1. 分区控制
2. Shuffle 控制
3. 数据存储、序列号、发送
4. 数据计算API



RDD（Resilient Distributed Dataset）弹性分布式数据集，是 Spark 中基本数据抽象，代表一个不可变可分区、可并行计算的数据集合

+ Dataset 数据集合
+ Distributed：RDD 中的数据是分布式存储的
+ Resilient：数据可以存在内存或磁盘中



### RDD五大特性

#### 1、RDD分区

一份RDD数据，本质上上分隔成了多个分区

```shell
>>> sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9], 3).glom().collect()
[[1, 2, 3], [4, 5, 6], [7, 8, 9]]
>>> sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9], 4).glom().collect()
[[1, 2], [3, 4], [5, 6], [7, 8, 9]]
```

#### 2、计算方法作用到每一块分片
在执行 map 操作将数据乘以 10 后，可以看到三个分区的数据都乘以10了
```shell
>>> rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> rdd.collect()
[1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> rdd.map(lambda x: x*10).collect()
[10, 20, 30, 40, 50, 60, 70, 80, 90]
```

#### 3、RDD之间有相互依赖关系
理解为参数传递，

#### 4、Key value RDD 可以有分区器
是一个可选性，默认分区器：Hash 分区规则，可以手动设置一个分区器（`rdd.partitionBy`的方法来设置的)，但并不是所有的 RDD 都是 K-V 型的

#### 5、RDD分区数据的读取尽量靠近数据所在地

在初始RDD读取数据的时候，分区会尽力规划到存储数据所在的服务器上，因为这样就可以走本地读取，避免网络读取。本地读取 Executor 所在服务器同样是 DataNode，同时这个 DataNode 上它要读的数据，可以直接读取机械硬盘即可，无需走网络传输。

