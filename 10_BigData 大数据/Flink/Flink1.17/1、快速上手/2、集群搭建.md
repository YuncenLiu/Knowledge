## 集群搭建

| Hadoop01                    | Hadoop02    | Hadoop03    |
| --------------------------- | ----------- | ----------- |
| JobManager<br />TaskManager | TaskManager | TaskManager |

#### 1、上传依赖

上传 `flink-1.17.0-bin-scala_2.12.tgz`  到 `Hadoop01` 节点，解压到 `/usr/local` 下

```sh
tar -zxvf flink-1.17.0-bin-scala_2.12.tgz -C /usr/local/
ln -s /usr/local/flink-1.17.0/ /usr/local/flink
```

#### 2、修改配置

进入 conf 路径，修改 `flink-conf.yaml` 文件

```yaml
# JobManager 节点
jobmanager.rpc.address: hadoop01
jobmanager.bind-host: 0.0.0.0
rest.address: hadoop01
rest.bind-address: 0.0.0.0

# TaskManager 节点
taskmanager.bind-host: 0.0.0.0
taskmanager.host: hadoop01
```

修改 `words` 文件

```properties
hadoop01
hadoop02
hadoop03
```

修改 `master` 文件

```properties
hadoop01:8081
```

#### 3、分发文件

```sh
sudo scp -r flink-1.17.0/ hadoop02:/usr/local
sudo scp -r flink-1.17.0/ hadoop03:/usr/local
```

#### 4、修改其他节点配置

##### Hadoop02

修改 `conf/flink-conf.yaml` 文件

```yaml
taskmanager.host: hadoop02
```

##### Hadoop03

修改 `conf/flink-conf.yaml` 文件

```yaml
taskmanager.host: hadoop03
```



#### 5、其他配置介绍

```yaml
jobmanager.memory.process.size: 1600m
# JobManager JVM 元空间，默认 1600M

taskmanager.memory.process.size: 1728m
# TaskManager JVM 元空间

taskmanager.numberOfTaskSlots: 1
# TaskManager Slot 数量

parallelism.default: 1
# 默认并行度
```



## 启动

```sh
bin/start-cluster.sh
```

![image-20231017153642252](images/2%E3%80%81%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/image-20231017153642252.png)

```shell
[xiang@hadoop01 flink]$ jps-cluster.sh 
----------  hadoop01  ----------
8195 TaskManagerRunner
7847 StandaloneSessionClusterEntrypoint
----------  hadoop02  ----------
2460 TaskManagerRunner
----------  hadoop03  ----------
2441 TaskManagerRunner
```

`StandaloneSessionClusterEntrypoint` 就是 `JobManager` 进程



访问地址：http://hadoop01:8081

![image-20231017154439155](images/2%E3%80%81%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/image-20231017154439155.png)



