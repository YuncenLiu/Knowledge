创建目录

```sh
hdfs dfs -mkdir /xiang
hdfs dfs -mkdir -p /xiang/a/b/c
```

上传命令

```sh
# hdfs dfs -put 本地文件 hadoop目录
hdfs dfs -put software/ /test/software

# 从本地拷贝到 hadoop 上，和 -put 一样
hdfs dfs -copyFromLocal a.txt /

# 从本地移动到 hadoop 上
hdfs dfs -moveFromLocal a.txt /  
```

查看目录

```sh
[-ls [d] [-h] [-R] [<path>] ...]
# 查看根目录
hdfs dfs -ls /

# 递归查看
hdfs dfs -ls -R /
```

查看文件

```sh
hdfs dfs -cat file1

hdfs dfs -tail file1
```

下载文件

```sh
# 把hadoop的 /input/file1 文件下载到本地根目录 
hdfs dfs -copyToLocal /input/file1 ~/

hdfs dfs -get /input/file1 ~/

# 如果不指定后续目录，就下载到当前执行命令的目录
hdfs dfs -get /input

# 合并下载，这里的第二个file文件不能省略
hdfs dfs -getmerger /input/file*  file
```

删除命令

```sh
# hadoop 内删除不需要确认，直接就删掉了
hdfs dfs -rm /file1

# 删目录
hdfs dfs -rm -r /test

# 删除非空的文件夹
hdfs dfs -rmdir /test
```

移动（重命名）命令

```sh
hdfs dfs -mv file1 file2
```

拷贝

```sh
hdfs dfs -cp file1 file1_back
# -cp 对目录也有效
```

创建空文件

```sh
hdfs dfs -touchz /file
```

向文件中追加内容

> HDFS 文件系统中，不允许进行文件中的数据插入、删除、修改操作，只支持向文件的末尾追加内容

```
hdfs dfs -appendToFile 本地文件 hdfs文件
```

修改权限

```sh
hdfs dfs -chmod 777 /file1

hdfs dfs -chmod -R 777 /file1

hdfs dfs -chown xiang:xiang /file1
```

修改文件副本数量

```sh
# 可以直接作用在文件 、 文件夹 上
hdfs dfs -setrep 5 /input
# 当作用在文件夹上时，从客户端只能看到子目录副本数被改为5，文件夹本身不改变
```

文件测试

```sh
# 判断这个 /input/file1 是不是文件夹，如果是打印 ok
hdfs dfs -test -d /input/file1 && echo "ok" || echo "no"

-e: 是否存在
-z: 是否为空
-d: 是否为文件夹
```

统计子文件数量

```sh
[xiang@hadoop01 input]$  hdfs dfs -count /input
           1            2                 75 /input
# 看中间那个数字，下面有2个文件           
```

查看磁盘

```sh
# 显示整个磁盘
hdfs dfs -df /
hdfs dfs -df -h /

# 查看某个目录
hdfs dfs -du -h /input

# 加上 -s 求总和
hdfs dfs -du -h -s /input
```

查看文件状态

```sh
hdfs dfs -stat %b-%n-%o-%r /input/file1

%b:文件大小，目录大小为0
%n:文件名
%o:block的size
%r:副本数
%y:上一次修改时间 yyyy-MM-dd HH:mm:ss
%Y:1970年1月1日以来，基数时间戳
%F:目录输出 directory，文件输出 regular file

# 当使用 -stat 不带参数时候，默认 %y
# -stat 后面只跟目录时候， %r %o 都是0，只有文件才有副本数
```

