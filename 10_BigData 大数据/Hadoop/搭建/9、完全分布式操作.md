```sh
# 用于单独启动或关闭hdfs的某一个守护进程脚本
# 在 hadoop2.x 的版本中命令为  hadoop-dameon.sh  在 hadoop3.x 是 hdfs 
hdfs --daemon start datanode
hdfs --daemon stop datanode

[start|stop] [namenode|datanode|secondarynamenode]
# 无论是启动哪个服务，都是在执行的当前节点，不能在 hadoop01 上启动 hadoop02的 secondarynamenode
# 只能启动当前节点部署好的服务
```



一键启动所有服务上的 datanode

```sh
# hadoop2.x 版本命令
hadoop-daemon.sh start datanode
# hadoop3.x 
hdfs --workers --daemon start datanode

hdfs --workers --daemon stop datanode
```



查看所有节点进程

创建一个脚本  `vim /opt/bin/jps-cluster.sh` 

```sh
#!/bin/bash

HOSTS=( hadoop01 hadoop02 hadoop03 )
for HOST in ${HOSTS[*]}
do
	echo "----------  $HOST  ----------"
	ssh -T $HOST << DELIMITER
	jps | grep -iv jps
	exit
DELIMITER
done
```

![image-20230326193203058](images/9、完全分布式操作/image-20230326193203058.png)

再软链到 /usr/bin 中

```sh
ln -s /opt/bin/jps-cluster.sh /usr/bin/
```

